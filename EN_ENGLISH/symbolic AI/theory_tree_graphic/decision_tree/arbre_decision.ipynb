{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
<<<<<<< Updated upstream
    "A decision tree is a tool that helps taking decisions by displaying an range of possible choices in the form of graphs or trees. In artificial intelligence a decision tree is a model capable of taking decisions depending on the provided data.\n",
=======
<<<<<<< HEAD
    "A decision tree is a tool that helps taking decisions by displaying an range of possible choices in the form of graphs or trees. In artificial intelligence a decision tree is a model capable of taking decisions based on the provided data.\n",
=======
    "A decision tree is a tool that helps taking decisions by displaying an range of possible choices in the form of graphs or trees. In artificial intelligence a decision tree is a model capable of taking decisions depending on the provided data.\n",
>>>>>>> c211a72b3c7293b79693174b46e2c3f2f26c5b23
>>>>>>> Stashed changes
    "\n",
    "## How a decision tree works with scheme\n",
    "\n",
    "![decision_tree.png](../../../../img/decision_tree.png)\n",
    "\n",
<<<<<<< Updated upstream
    "The decision tree builds itself as it goes along . At the start, the whole data available is considered at the root of our tree. Our algorithm will next select a data characteristic from the data to divide them into data sets. Our goal is to choose the characteristic that best divides the data in order to form homogeneous subgroups. Once we have chosen the characteristics we divide our data and each subgroup corresponding to a branch of our tree. This process is repeated until reaching a criteria for arrest so a leaf node.\n",
=======
<<<<<<< HEAD
    "The decision tree builds itself as it goes along . At the start, the data available is considered at the root of our tree. Our algorithm will next select a data characteristic from the data to divide them into data sets. Our goal is to choose the characteristic that best divides the data in order to form homogeneous subgroups. Once we have chosen the characteristics we divide our data and each subgroup corresponding to a branch of our tree. This process is repeated until a criteria for arrest is reached (so a leaf node).\n",
=======
    "The decision tree builds itself as it goes along . At the start, the whole data available is considered at the root of our tree. Our algorithm will next select a data characteristic from the data to divide them into data sets. Our goal is to choose the characteristic that best divides the data in order to form homogeneous subgroups. Once we have chosen the characteristics we divide our data and each subgroup corresponding to a branch of our tree. This process is repeated until reaching a criteria for arrest so a leaf node.\n",
>>>>>>> c211a72b3c7293b79693174b46e2c3f2f26c5b23
>>>>>>> Stashed changes
    "\n",
    "To sum up, as we divide the data, the tree builds itself. Each node corresponds to a dividing characteristic, each branch corresponds to a possible value of this characteristic and each leaf node represents a prediction or a class.\n",
    "\n",
    "Root :\n",
    "- The tree's root represents the data set used by the algorithm.\n",
    "\n",
    "Branch :\n",
    "- It represents a possible value of a characteristic.\n",
    "\n",
    "Node :\n",
<<<<<<< Updated upstream
    "- The node represents a characteristic to divide the data.\n",
=======
<<<<<<< HEAD
    "- The node represents a dividing characteristic.\n",
=======
    "- The node represents a characteristic to divide the data.\n",
>>>>>>> c211a72b3c7293b79693174b46e2c3f2f26c5b23
>>>>>>> Stashed changes
    "\n",
    "Leaf node :\n",
    "- The branches end by leaf nodes, and those represents the final outputs of our decision tree.\n",
    "\n",
    "Now we're going to see different algorithms to create decision trees and see the different libraries that implement them to resolve problems with these decision trees."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
